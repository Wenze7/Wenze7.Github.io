<!DOCTYPE html>
<html  lang="zh">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>educoder数据挖掘算法原理与实践：ID3决策树 - Wenze7&#39;blog</title>


    <meta name="description" content="引例在炎热的夏天，没有什么比冰镇后的西瓜更能令人感到心旷神怡的了。现在我要去水果店买西瓜，但什么样的西瓜能入我法眼呢？那根据我的个人习惯，在挑西瓜时可能就有这样的脑回路。">
<meta property="og:type" content="article">
<meta property="og:title" content="educoder数据挖掘算法原理与实践：ID3决策树">
<meta property="og:url" content="http://yoursite.com/2020/04/14/educoder%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9AID3%E5%86%B3%E7%AD%96%E6%A0%91/index.html">
<meta property="og:site_name" content="Wenze7&#39;blog">
<meta property="og:description" content="引例在炎热的夏天，没有什么比冰镇后的西瓜更能令人感到心旷神怡的了。现在我要去水果店买西瓜，但什么样的西瓜能入我法眼呢？那根据我的个人习惯，在挑西瓜时可能就有这样的脑回路。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/images/og_image.png">
<meta property="article:published_time" content="2020-04-14T09:12:03.756Z">
<meta property="article:modified_time" content="2020-04-15T06:15:39.051Z">
<meta property="article:author" content="Wenze7">
<meta property="article:tag" content="ID3">
<meta property="article:tag" content="决策树">
<meta property="article:tag" content="educoder">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/og_image.png">







<link rel="icon" href="/images/favicon.jpeg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?9f2147f89cfdfc1c96777c46d87fed3a";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script>
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">



</head>
<body class="is-2-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="educoder数据挖掘算法原理与实践：ID3决策树" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">主页</a>
                
                <a class="navbar-item"
                href="/archives">归档</a>
                
                <a class="navbar-item"
                href="/categories">分类</a>
                
                <a class="navbar-item"
                href="/tags">标签</a>
                
                <a class="navbar-item"
                href="/about">关于</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Wenze7">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="搜索" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main">
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-14T09:12:03.756Z">2020-04-14</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    26 分钟 读完 (大约 3951 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                educoder数据挖掘算法原理与实践：ID3决策树
            
        </h1>
        <div class="content">
            <h3 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h3><p>在炎热的夏天，没有什么比冰镇后的西瓜更能令人感到心旷神怡的了。现在我要去水果店买西瓜，但什么样的西瓜能入我法眼呢？那根据我的个人习惯，在挑西瓜时可能就有这样的脑回路。<br><img src="https://www.educoder.net/api/attachments/283157"></img></p>
<a id="more"></a>
<p>假设现在水果店里有3个西瓜，它们的属性如下：<br><img src="https://s1.ax1x.com/2020/04/14/JS1GBn.jpg" alt="JS1GBn.jpg"><br>那么根据我的脑回路我会买1和2号西瓜。<br>其实我的脑回路可以看成一棵树，并且这颗树能够帮助我对买不买西瓜这件事做决策，所以它就是一棵决策树。</p>
<h3 id="决策树的相关概念"><a href="#决策树的相关概念" class="headerlink" title="决策树的相关概念"></a>决策树的相关概念</h3><p>决策树是一种可以用于分类与回归的机器学习算法，但主要用于分类。用于分类的决策树是一种描述对实例进行分类的树形结构。决策树由结点和边<strong>组成，其中结点分为内部结点和</strong>叶子结点，内部结点表示一个特征或者属性，叶子结点表示标签（脑回路图中黄色的是内部结点，蓝色的是叶子结点）。</p>
<p>从代码角度来看，决策树其实可以看成是一堆if-else语句的集合，例如引例中的决策树完全可以看成是如下代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> isRed:</span><br><span class="line">    <span class="keyword">if</span> isCold:</span><br><span class="line">        <span class="keyword">if</span> hasSeed:</span><br><span class="line">            print(<span class="string">"buy"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"don't buy"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> isCheap:</span><br><span class="line">            print(<span class="string">"buy"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"don't buy"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"don't buy"</span>)</span><br></pre></td></tr></table></figure>
<p>因此决策树的一个非常大的优势就是模型的可理解性非常高，甚至可以用来挖掘数据中比较重要的信息。</p>
<p>那么如何构造出一棵好的决策树呢？其实构造决策树时会遵循一个指标，有的是按照信息增益来构建，如ID3算法；有的是信息增益率来构建，如C4.5算法；有的是按照基尼系数来构建的，如CART算法。但不管是使用哪种构建算法，决策树的构建过程通常都是一个递归选择最优特征，并根据特征对训练集进行分割，使得对各个子数据集有一个最好的分类的过程。</p>
<p>这一过程对应着对特征空间的划分，也对应着决策树的构建。一开始，构建决策树的根结点，将所有训练数据都放在根结点。选择一个最优特征，并按照这一特征将训练数据集分割成子集，使得各个子集有一个在当前条件下最好的分类。如果这些子集已经能够被基本正确分类，那么构建叶子结点，并将这些子集分到所对应的叶结点中去；如果还有子集不能被基本正确分类，那么就对这些子集选择新的最优特征，继续对其进行分割，并构建相应的结点。如此递归进行下去，直至所有训练数据子集被基本正确分类，或者没有合适的特征为止。最后每个子集都被分到叶子结点上，即都有了明确的类别。这就构建出了一棵决策树。</p>
<h4 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h4><p>信息是个很抽象的概念。人们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。比如一本五十万字的中文书到底有多少信息量。</p>
<p>直到1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。信息熵这个词是香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。信源的不确定性越大，信息熵也越大。</p>
<p>从机器学习的角度来看，信息熵表示的是信息量的期望值。如果数据集中的数据需要被分成多个类别，则信息量 $I(x_i)$ 的定义如下(其中$x_i$表示多个类别中的第i个类，$p(x_i)$数据集中类别为$x_i$的数据在数据集中出现的概率表示)：<br>$$I(X_i)=-log_2p(x_i)$$<br>由于信息熵是信息量的期望值，所以信息熵H(X)的定义如下(其中n为数据集中类别的数量)：<br>$$H(X)=-\sum_{i=1}^{n}p(x_i)log_2p(x_i)$$</p>
<p>从这个公式也可以看出，如果概率是0或者是1的时候，熵就是0。（因为这种情况下随机变量的不确定性是最低的），那如果概率是0.5也就是五五开的时候，此时熵达到最大，也就是1。（就像扔硬币，你永远都猜不透你下次扔到的是正面还是反面，所以它的不确定性非常高）。所以呢，熵越大，不确定性就越高。</p>
<h4 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h4><p>在实际的场景中，我们可能需要研究数据集中某个特征等于某个值时的信息熵等于多少，这个时候就需要用到条件熵。条件熵H(Y|X)表示特征X为某个值的条件下，类别为Y的熵。条件熵的计算公式如下：</p>
<p>$$H(Y|X)=\sum^{n}_{i=1}p_iH(Y|X=x_i)$$</p>
<p>当然条件熵的一个性质也熵的性质一样，概率越确定，条件熵就越小，概率越五五开，条件熵就越大。</p>
<h4 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h4><p>现在已经知道了什么是熵，什么是条件熵。接下来就可以看看什么是信息增益了。所谓的信息增益就是表示我已知条件X后能得到信息Y的不确定性的减少程度。</p>
<p>就好比，我在玩读心术。你心里想一件东西，我来猜。我已开始什么都没问你，我要猜的话，肯定是瞎猜。这个时候我的熵就非常高。然后我接下来我会去试着问你是非题，当我问了是非题之后，我就能减小猜测你心中想到的东西的范围，这样其实就是减小了我的熵。那么我熵的减小程度就是我的信息增益。</p>
<p>所以信息增益如果套上机器学习的话就是，如果把特征A对训练集D的信息增益记为g(D, A)的话，那么g(D, A)的计算公式就是：</p>
<p>$$g(D, A)=H(D)-H(D,A)g(D,A)=H(D)−H(D,A)$$</p>
<p>为了更好的解释熵，条件熵，信息增益的计算过程，下面通过示例来描述。假设我现在有这一个数据集，第一列是编号，第二列是性别，第三列是活跃度，第四列是客户是否流失的标签（0:表示未流失，1:表示流失）。<br><img src="https://s1.ax1x.com/2020/04/14/JS3ozF.jpg" alt="JS3ozF.jpg"><br>假如要算性别和活跃度这两个特征的信息增益的话，首先要先算总的熵和条件熵。总的熵其实非常好算，就是把标签作为随机变量X。上表中标签只有两种（0和1）因此随机变量X的取值只有0或者1。所以要计算熵就需要先分别计算标签为0的概率和标签为1的概率。从表中能看出标签为0的数据有10条，所以标签为0的概率等于2/3。标签为1的概率为1/3。所以熵为：</p>
<p>$$-(1/3)*log(1/3)-(2/3)*log(2/3)=0.9182−(1/3)∗log(1/3)−(2/3)∗log(2/3)=0.9182$$</p>
<p>接下来就是条件熵的计算，以性别为男的熵为例。表格中性别为男的数据有8条，这8条数据中有3条数据的标签为1，有5条数据的标签为0。所以根据条件熵的计算公式能够得出该条件熵为：</p>
<p>$$-(3/8)*log(3/8)-(5/8)*log(5/8)=0.9543−(3/8)∗log(3/8)−(5/8)∗log(5/8)=0.9543$$</p>
<p>根据上述的计算方法可知，总熵为：</p>
<p>$$-(5/15)*log(5/15)-(10/15)*log(10/15)=0.9182−(5/15)∗log(5/15)−(10/15)∗log(10/15)=0.9182$$</p>
<p>性别为男的熵为：</p>
<p>$$-(3/8)*log(3/8)-(5/8)*log(5/8)=0.9543−(3/8)∗log(3/8)−(5/8)∗log(5/8)=0.9543$$</p>
<p>性别为女的熵为：</p>
<p>$$-(2/7)*log(2/7)-(5/7)*log(5/7)=0.8631−(2/7)∗log(2/7)−(5/7)∗log(5/7)=0.8631$$</p>
<p>活跃度为低的熵为：</p>
<p>$$-(4/4)*log(4/4)-0=0−(4/4)\∗log(4/4)−0=0$$</p>
<p>活跃度为中的熵为：</p>
<p>$$-(1/5)*log(1/5)-(4/5)*log(4/5)=0.7219−(1/5)∗log(1/5)−(4/5)∗log(4/5)=0.7219$$</p>
<p>活跃度为高的熵为：</p>
<p>$$-0-(6/6)*log(6/6)=0−0−(6/6)∗log(6/6)=0$$</p>
<p>现在有了总的熵和条件熵之后就能算出性别和活跃度这两个特征的信息增益了。</p>
<p>性别的信息增益=总的熵-(8/15)性别为男的熵-(7/15)性别为女的熵=0.0064</p>
<p>活跃度的信息增益=总的熵-(6/15)活跃度为高的熵-(5/15)活跃度为中的熵-(4/15)*活跃度为低的熵=0.6776</p>
<p>那信息增益算出来之后有什么意义呢？回到读心术的问题，为了我能更加准确的猜出你心中所想，我肯定是问的问题越好就能猜得越准！换句话来说我肯定是要想出一个信息增益最大（减少不确定性程度最高）的问题来问你。其实ID3算法也是这么想的。ID3算法的思想是从训练集D中计算每个特征的信息增益，然后看哪个最大就选哪个作为当前结点。然后继续重复刚刚的步骤来构建决策树。</p>
<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p>就是从根结点开始，对结点计算所有可能的特征的信息增益，然后选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点，然后对子结点递归执行上述的步骤直到信息增益很小或者没有特征可以继续选择为止。</p>
<p>因此，ID3算法伪代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#假设数据集为D，标签集为A，需要构造的决策树为tree</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ID3</span><span class="params">(D, A)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> D中所有的标签都相同:</span><br><span class="line">        <span class="keyword">return</span> 标签</span><br><span class="line">    <span class="keyword">if</span> 样本中只有一个特征或者所有样本的特征都一样:</span><br><span class="line">        对D中所有的标签进行计数</span><br><span class="line">        <span class="keyword">return</span> 计数最高的标签</span><br><span class="line">    计算所有特征的信息增益</span><br><span class="line">    选出增益最大的特征作为最佳特征(best_feature)</span><br><span class="line">    将best_feature作为tree的根结点</span><br><span class="line">    得到best_feature在数据集中所有出现过的值的集合(value_set)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> value_set:</span><br><span class="line">        从D中筛选出best_feature=value的子数据集(sub_feature)</span><br><span class="line">        从A中筛选出best_feature=value的子标签集(sub_label)</span><br><span class="line">        <span class="comment">#递归构造tree</span></span><br><span class="line">        tree[best_feature][value] = ID3(sub_feature, sub_label)</span><br><span class="line">    <span class="keyword">return</span> tree</span><br></pre></td></tr></table></figure>
<h3 id="使用决策树进行预测"><a href="#使用决策树进行预测" class="headerlink" title="使用决策树进行预测"></a>使用决策树进行预测</h3><p>决策树的预测思想非常简单，假设现在已经构建出了一棵用来决策是否买西瓜的决策树。<br><img src="https://www.educoder.net/api/attachments/283157"></img></p>
<p>并假设现在在水果店里有这样一个西瓜，其属性如下：<br><img src="https://s1.ax1x.com/2020/04/14/JSGEnJ.jpg" alt="JSGEnJ.jpg"><br>那买不买这个西瓜呢？只需把西瓜的属性代入决策树即可。决策树的根结点是瓤是否够红，所以就看西瓜的属性，经查看发现够红，因此接下来就看够不够冰。而西瓜不够冰，那么看是否便宜。发现西瓜是便宜的，所以这个西瓜是可以买的。</p>
<p>因此使用决策树进行预测的伪代码也比较简单，伪代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tree表示决策树，feature表示测试数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(tree, feature)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> tree是叶子结点:</span><br><span class="line">        <span class="keyword">return</span> tree</span><br><span class="line">    根据feature中的特征值走入tree中对应的分支</span><br><span class="line">    <span class="keyword">if</span> 分支依然是课树:</span><br><span class="line">        result = predict(分支, feature)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding=utf8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 计算熵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcInfoEntropy</span><span class="params">(label)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        label(narray):样本标签</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        InfoEntropy(float):熵</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#********* Begin *********#</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算标签在数据集中出现的概率</span></span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> label:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">            dic[i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dic[i] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 计算熵</span></span><br><span class="line">    num = len(label)</span><br><span class="line">    InfoEntropy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> dic:</span><br><span class="line">        InfoEntropy += <span class="number">-1.0</span>*dic[key]/num*np.log2(<span class="number">1.0</span>*dic[key]/num)</span><br><span class="line">    <span class="comment">#********* End *********#</span></span><br><span class="line">    <span class="keyword">return</span> InfoEntropy</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算条件熵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcHDA</span><span class="params">(feature, label, index, value)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarray):样本特征</span></span><br><span class="line"><span class="string">        label(ndarray):样本标签</span></span><br><span class="line"><span class="string">        index(int):需要使用的特征列索引</span></span><br><span class="line"><span class="string">        value(int):index所表示的特征列中需要考察的特征值</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        HDA(float):信息熵</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#********* Begin *********#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># sub_feature和sub_label表示根据特征列和特征值分割出的子数据集中的特征和标签</span></span><br><span class="line">    sub_feature = []</span><br><span class="line">    sub_label = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(feature)):</span><br><span class="line">        <span class="keyword">if</span> feature[i,index] == value:</span><br><span class="line">            sub_feature.append(feature[i])</span><br><span class="line">            sub_label.append(label[i])</span><br><span class="line"></span><br><span class="line">    sub_feature = np.array(sub_feature)</span><br><span class="line">    sub_label = np.array(sub_label)</span><br><span class="line">    HDA = calcInfoEntropy(sub_label)</span><br><span class="line">    <span class="comment">#********* End *********#</span></span><br><span class="line">    <span class="keyword">return</span> HDA</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算信息增益</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcInfoGain</span><span class="params">(feature, label, index)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarry):测试用例中字典里的feature</span></span><br><span class="line"><span class="string">        label(ndarray):测试用例中字典里的label</span></span><br><span class="line"><span class="string">        index(int):测试用例中字典里的index，即feature部分特征列的索引。该索引指的是feature中第几个特征，如index:0表示使用第一个特征来计算信息增益。</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        InfoGain(float):信息增益</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#********* Begin *********#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 得到指定特征列的值的集合</span></span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> feature[:,index]:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">            dic[i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dic[i] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算条件熵</span></span><br><span class="line">    HDA = <span class="number">0</span></span><br><span class="line">    num = len(feature)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> dic:</span><br><span class="line">        HDA += <span class="number">1.0</span>*dic[key]/num*calcHDA(feature,label,index,key)</span><br><span class="line">    <span class="comment"># 计算信息增益</span></span><br><span class="line">    InfoGain = calcInfoEntropy(label) - HDA</span><br><span class="line">    <span class="comment">#********* End *********#</span></span><br><span class="line">    <span class="keyword">return</span> InfoGain</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#&#123;'feature':[[0, 1], [1, 0], [1, 2], [0, 0], [1, 1]], 'label':[0, 1, 0, 0, 1], 'index': 0&#125;</span></span><br><span class="line"><span class="comment">#0.419973</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getBestFeature</span><span class="params">(feature, label)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarray):样本特征</span></span><br><span class="line"><span class="string">        label(ndarray):样本标签</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        best_feature(int):信息增益最高的特征</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#*********Begin*********#</span></span><br><span class="line">    maxInfoGain,opIndex = <span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> range(feature.shape[<span class="number">1</span>]):</span><br><span class="line">        infoGain = calcInfoGain(feature,label,index)</span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; maxInfoGain:</span><br><span class="line">            maxInfoGain = infoGain</span><br><span class="line">            opIndex = index</span><br><span class="line">    <span class="comment">#*********End*********#</span></span><br><span class="line">    <span class="keyword">return</span> opIndex</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建决策树</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(feature, label)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarray):训练样本特征</span></span><br><span class="line"><span class="string">        label(ndarray):训练样本标签</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        tree(dict):决策树模型</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#*********Begin*********#</span></span><br><span class="line">    <span class="comment"># 样本里都是同一个label没必要继续分叉了</span></span><br><span class="line">    label_set = set(label)</span><br><span class="line">    <span class="keyword">if</span>(label_set.__len__()==<span class="number">1</span>):<span class="keyword">return</span> label[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 样本中只有一个特或者所有样本的特征都一样的话就看哪个label的票数高</span></span><br><span class="line">    flag = <span class="literal">True</span></span><br><span class="line">    arr = feature[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> arrs <span class="keyword">in</span> feature:</span><br><span class="line">        <span class="keyword">if</span> str(arr) != str(arrs) : flag = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="literal">True</span>:</span><br><span class="line">        dic = &#123;&#125;</span><br><span class="line">        MAX = <span class="number">0</span></span><br><span class="line">        l = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> label:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">                dic[i] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                dic[i] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> dic[i] &gt; MAX:</span><br><span class="line">                MAX = dic[i]</span><br><span class="line">                l = i</span><br><span class="line">        <span class="keyword">return</span> l</span><br><span class="line">    <span class="comment"># 根据信息增益拿到特征的索引</span></span><br><span class="line">    best_feature = getBestFeature(feature,label)</span><br><span class="line">    <span class="comment"># 拿到bestfeature的所有特征值</span></span><br><span class="line">    v_set = set(feature[:,best_feature])</span><br><span class="line">    <span class="comment"># 构建对应特征值的子样本集sub_feature, sub_label</span></span><br><span class="line">    tree = &#123;best_feature:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> v_set:</span><br><span class="line">        sub_feature = []</span><br><span class="line">        sub_label = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(feature)):</span><br><span class="line">            <span class="keyword">if</span> feature[i][best_feature] == value:</span><br><span class="line">                sub_feature.append(feature[i])</span><br><span class="line">                sub_label.append(label[i])</span><br><span class="line"></span><br><span class="line">        sub_feature = np.array(sub_feature)</span><br><span class="line">        sub_label = np.array(sub_label)</span><br><span class="line">        <span class="comment"># 递归构建决策树</span></span><br><span class="line">        tree[best_feature][value] = createTree(sub_feature,sub_label)</span><br><span class="line">    <span class="comment">#*********End*********#</span></span><br><span class="line">    <span class="keyword">return</span> tree</span><br><span class="line"></span><br><span class="line"><span class="comment">#决策树分类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dt_clf</span><span class="params">(train_feature,train_label,test_feature)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        train_feature(ndarray):训练样本特征</span></span><br><span class="line"><span class="string">        train_label(ndarray):训练样本标签</span></span><br><span class="line"><span class="string">        test_feature(ndarray):测试样本特征</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        predict(ndarray):测试样本预测标签</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#*********Begin*********#</span></span><br><span class="line">    <span class="comment">#创建决策树</span></span><br><span class="line">    nowTree = createTree(train_feature,train_label)</span><br><span class="line">    <span class="comment">#print(tree)</span></span><br><span class="line">    <span class="comment">#根据tree与特征进行分类</span></span><br><span class="line">    predict = []</span><br><span class="line">    <span class="keyword">for</span> arr <span class="keyword">in</span> test_feature:</span><br><span class="line">        tree = nowTree.copy()</span><br><span class="line">        print(tree)</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">            <span class="comment">#print(tree)</span></span><br><span class="line">            <span class="keyword">if</span> type(tree).__name__ != <span class="string">'dict'</span>:</span><br><span class="line">                predict.append(tree)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            keyList = list(tree.keys())</span><br><span class="line">            firstF = keyList[<span class="number">0</span>]</span><br><span class="line">            tree = tree[firstF][arr[firstF]]</span><br><span class="line">    <span class="comment">#*********End*********#</span></span><br><span class="line">    <span class="keyword">return</span> predict</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">x = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">train_feature,test_feature,train_label,test_label = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</span><br><span class="line">predict = dt_clf(test_feature,train_label,test_feature)</span><br><span class="line">print(predict)</span><br></pre></td></tr></table></figure>

        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/ID3/" rel="tag">ID3</a>, <a class="has-link-grey -link" href="/tags/educoder/" rel="tag">educoder</a>, <a class="has-link-grey -link" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" rel="tag">决策树</a>
                </div>
            </div>
        </div>
        
        
        
        <div class="social-share"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css">
<script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script>
        
    </div>
</div>




<div class="card">
    <div class="card-content">
        <h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3>
        <div class="buttons is-centered">
            
                
<a class="button is-info donate">
    <span class="icon is-small">
        <i class="fab fa-alipay"></i>
    </span>
    <span>支付宝</span>
    <div class="qrcode"><img src="/images/zfb.JPG" alt="支付宝"></div>
</a>

                
                
<a class="button is-success donate">
    <span class="icon is-small">
        <i class="fab fa-weixin"></i>
    </span>
    <span>微信</span>
    <div class="qrcode"><img src="/images/wx.JPG" alt="微信"></div>
</a>

                
        </div>
    </div>
</div>



<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2020/04/15/educoder%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9Ak%E8%BF%91%E9%82%BB/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">educoder数据挖掘算法原理与实践：k近邻</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2020/04/09/educoder%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%EF%BC%89/">
                <span class="level-item">educoder数据挖掘算法原理与实践：线性回归（房价预测）</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>





<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">评论</h3>
        
<div id="valine-thread" class="content"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>
<script>
    new Valine({
        el: '#valine-thread' ,
        notify: false,
        verify: false,
        app_id: 'O0P4snqgLnmubqnDqIS8jbqj-gzGzoHsz',
        app_key: 'MYxx6TUU4WMljOulxHav5K3s',
        placeholder: '如有不当之处，敬请指正！'
    });
</script>

    </div>
</div>






    
</div>
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="" src="/images/avatar.jpg" alt="Wenze7">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Wenze7
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        NONE
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>ShanDong,QingDao</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        文章
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            18
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        分类
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            6
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        标签
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            15
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/wenze7" target="_blank" rel="noopener">
                关注我</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Github" href="https://github.com/wenze7">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Weibo" href="https://weibo.com/5663670406/profile?topnav=1&amp;wvr=6dd">
                
                <i class="fab fa-weibo"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Zhihu" href="https://www.zhihu.com/people/pengqiu7">
                
                <i class="fab fa-zhihu"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="QQ" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1245666720&amp;site=qq&amp;menu=yes">
                
                <i class="fab fa-qq"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Twitter" href="http://www.baidu.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        

    <div class="card widget" id="toc">
        <div class="card-content">
            <div class="menu">
                <h3 class="menu-label">
                    目录
                </h3>
                <ul class="menu-list"><li>
        <a class="is-flex" href="#引例">
        <span class="has-mr-6">1</span>
        <span>引例</span>
        </a></li><li>
        <a class="is-flex" href="#决策树的相关概念">
        <span class="has-mr-6">2</span>
        <span>决策树的相关概念</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#信息熵">
        <span class="has-mr-6">2.1</span>
        <span>信息熵</span>
        </a></li><li>
        <a class="is-flex" href="#条件熵">
        <span class="has-mr-6">2.2</span>
        <span>条件熵</span>
        </a></li><li>
        <a class="is-flex" href="#信息增益">
        <span class="has-mr-6">2.3</span>
        <span>信息增益</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#ID3算法">
        <span class="has-mr-6">3</span>
        <span>ID3算法</span>
        </a></li><li>
        <a class="is-flex" href="#使用决策树进行预测">
        <span class="has-mr-6">4</span>
        <span>使用决策树进行预测</span>
        </a></li><li>
        <a class="is-flex" href="#代码">
        <span class="has-mr-6">5</span>
        <span>代码</span>
        </a></li></ul>
            </div>
        </div>
    </div>

    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            链接
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://catbox.moe" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">catbox</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">catbox.moe</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://blog.csdn.net/Insist_77" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">CSDN</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">blog.csdn.net</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                分类
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
            <span class="level-start">
                <span class="level-item">学习笔记</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E6%80%BB%E7%BB%93/">
            <span class="level-start">
                <span class="level-item">总结</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">
            <span class="level-start">
                <span class="level-item">推荐系统</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E6%95%99%E7%A8%8B/">
            <span class="level-start">
                <span class="level-item">教程</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">
            <span class="level-start">
                <span class="level-item">数据挖掘</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">10</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E8%B5%84%E6%BA%90%E6%80%BB%E7%BB%93/">
            <span class="level-start">
                <span class="level-item">资源总结</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            标签云
        </h3>
        <a href="/tags/CART/" style="font-size: 10px;">CART</a> <a href="/tags/ID3/" style="font-size: 10px;">ID3</a> <a href="/tags/K-means/" style="font-size: 10px;">K-means</a> <a href="/tags/KNN/" style="font-size: 10px;">KNN</a> <a href="/tags/MAC/" style="font-size: 13.33px;">MAC</a> <a href="/tags/educoder/" style="font-size: 20px;">educoder</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/%E4%B8%8D%E5%AE%9A%E6%97%B6%E6%9B%B4%E6%96%B0/" style="font-size: 10px;">不定时更新</a> <a href="/tags/%E4%BF%9D%E7%A0%94/" style="font-size: 10px;">保研</a> <a href="/tags/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98/" style="font-size: 13.33px;">关联规则挖掘</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 16.67px;">决策树</a> <a href="/tags/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">多元线性回归</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 10px;">爬虫</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 13.33px;">神经网络</a> <a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86/" style="font-size: 10px;">贝叶斯定理</a>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            归档
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2021/09/">
                <span class="level-start">
                    <span class="level-item">九月 2021</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/10/">
                <span class="level-start">
                    <span class="level-item">十月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/08/">
                <span class="level-start">
                    <span class="level-item">八月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">四月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">三月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">5</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">二月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
        </div>
    
</div>

                
            </div>
        </div>
    </section>
    

<footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="educoder数据挖掘算法原理与实践：ID3决策树" height="28">
                
                </a>
                <p class="is-size-7">
          
                <!- &copy;  2021  Wenze7&nbsp;->
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
               
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
   
</footer>


    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("zh-CN");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'http://yoursite.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="回到顶端" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="想要查找什么..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
