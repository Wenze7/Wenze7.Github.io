<!DOCTYPE html>
<html  lang="zh">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>分类: 数据挖掘 - Seven7777777&#39;blog</title>


    <meta property="og:type" content="website">
<meta property="og:title" content="Seven7777777&#39;blog">
<meta property="og:url" content="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/index.html">
<meta property="og:site_name" content="Seven7777777&#39;blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/images/og_image.png">
<meta property="article:author" content="QiuPeng">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/og_image.png">







<link rel="icon" href="/images/favicon.jpeg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?9f2147f89cfdfc1c96777c46d87fed3a";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script>
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">



</head>
<body class="is-2-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                Seven7
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">主页</a>
                
                <a class="navbar-item"
                href="/archives">归档</a>
                
                <a class="navbar-item"
                href="/categories">分类</a>
                
                <a class="navbar-item"
                href="/tags">标签</a>
                
                <a class="navbar-item"
                href="/about">关于</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/wenze7">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="搜索" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main"><div class="card">
    <div class="card-content">
        <nav class="breadcrumb" aria-label="breadcrumbs">
        <ul>
            <li><a href="/categories">分类</a></li>
            
            <li class="is-active"><a href="#" aria-current="page">数据挖掘</a></li>
        </ul>
        </nav>
    </div>
</div>

    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-14T09:12:03.756Z">2020-04-14</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    26 分钟 读完 (大约 3950 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/14/educoder%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9AID3%E5%86%B3%E7%AD%96%E6%A0%91/">educoder数据挖掘算法原理与实践：ID3决策树</a>
            
        </h1>
        <div class="content">
            <h3 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h3><p>在炎热的夏天，没有什么比冰镇后的西瓜更能令人感到心旷神怡的了。现在我要去水果店买西瓜，但什么样的西瓜能入我法眼呢？那根据我的个人习惯，在挑西瓜时可能就有这样的脑回路。<br><img src="https://www.educoder.net/api/attachments/283157"></img><br>假设现在水果店里有3个西瓜，它们的属性如下：<br><img src="https://s1.ax1x.com/2020/04/14/JS1GBn.jpg" alt="JS1GBn.jpg"><br>那么根据我的脑回路我会买1和2号西瓜。<br>其实我的脑回路可以看成一棵树，并且这颗树能够帮助我对买不买西瓜这件事做决策，所以它就是一棵决策树。</p>
<h3 id="决策树的相关概念"><a href="#决策树的相关概念" class="headerlink" title="决策树的相关概念"></a>决策树的相关概念</h3><p>决策树是一种可以用于分类与回归的机器学习算法，但主要用于分类。用于分类的决策树是一种描述对实例进行分类的树形结构。决策树由结点和边<strong>组成，其中结点分为内部结点和</strong>叶子结点，内部结点表示一个特征或者属性，叶子结点表示标签（脑回路图中黄色的是内部结点，蓝色的是叶子结点）。</p>
<p>从代码角度来看，决策树其实可以看成是一堆if-else语句的集合，例如引例中的决策树完全可以看成是如下代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> isRed:</span><br><span class="line">    <span class="keyword">if</span> isCold:</span><br><span class="line">        <span class="keyword">if</span> hasSeed:</span><br><span class="line">            print(<span class="string">"buy"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"don't buy"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> isCheap:</span><br><span class="line">            print(<span class="string">"buy"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"don't buy"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"don't buy"</span>)</span><br></pre></td></tr></table></figure>
<p>因此决策树的一个非常大的优势就是模型的可理解性非常高，甚至可以用来挖掘数据中比较重要的信息。</p>
<p>那么如何构造出一棵好的决策树呢？其实构造决策树时会遵循一个指标，有的是按照信息增益来构建，如ID3算法；有的是信息增益率来构建，如C4.5算法；有的是按照基尼系数来构建的，如CART算法。但不管是使用哪种构建算法，决策树的构建过程通常都是一个递归选择最优特征，并根据特征对训练集进行分割，使得对各个子数据集有一个最好的分类的过程。</p>
<p>这一过程对应着对特征空间的划分，也对应着决策树的构建。一开始，构建决策树的根结点，将所有训练数据都放在根结点。选择一个最优特征，并按照这一特征将训练数据集分割成子集，使得各个子集有一个在当前条件下最好的分类。如果这些子集已经能够被基本正确分类，那么构建叶子结点，并将这些子集分到所对应的叶结点中去；如果还有子集不能被基本正确分类，那么就对这些子集选择新的最优特征，继续对其进行分割，并构建相应的结点。如此递归进行下去，直至所有训练数据子集被基本正确分类，或者没有合适的特征为止。最后每个子集都被分到叶子结点上，即都有了明确的类别。这就构建出了一棵决策树。</p>
<h4 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h4><p>信息是个很抽象的概念。人们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。比如一本五十万字的中文书到底有多少信息量。</p>
<p>直到1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。信息熵这个词是香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。信源的不确定性越大，信息熵也越大。</p>
<p>从机器学习的角度来看，信息熵表示的是信息量的期望值。如果数据集中的数据需要被分成多个类别，则信息量 $I(x_i)$ 的定义如下(其中$x_i$表示多个类别中的第i个类，$p(x_i)$数据集中类别为$x_i$的数据在数据集中出现的概率表示)：<br>$$I(X_i)=-log_2p(x_i)$$<br>由于信息熵是信息量的期望值，所以信息熵H(X)的定义如下(其中n为数据集中类别的数量)：<br>$$H(X)=-\sum_{i=1}^{n}p(x_i)log_2p(x_i)$$</p>
<p>从这个公式也可以看出，如果概率是0或者是1的时候，熵就是0。（因为这种情况下随机变量的不确定性是最低的），那如果概率是0.5也就是五五开的时候，此时熵达到最大，也就是1。（就像扔硬币，你永远都猜不透你下次扔到的是正面还是反面，所以它的不确定性非常高）。所以呢，熵越大，不确定性就越高。</p>
<h4 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h4><p>在实际的场景中，我们可能需要研究数据集中某个特征等于某个值时的信息熵等于多少，这个时候就需要用到条件熵。条件熵H(Y|X)表示特征X为某个值的条件下，类别为Y的熵。条件熵的计算公式如下：</p>
<p>$$H(Y|X)=\sum^{n}_{i=1}p_iH(Y|X=x_i)$$</p>
<p>当然条件熵的一个性质也熵的性质一样，概率越确定，条件熵就越小，概率越五五开，条件熵就越大。</p>
<h4 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h4><p>现在已经知道了什么是熵，什么是条件熵。接下来就可以看看什么是信息增益了。所谓的信息增益就是表示我已知条件X后能得到信息Y的不确定性的减少程度。</p>
<p>就好比，我在玩读心术。你心里想一件东西，我来猜。我已开始什么都没问你，我要猜的话，肯定是瞎猜。这个时候我的熵就非常高。然后我接下来我会去试着问你是非题，当我问了是非题之后，我就能减小猜测你心中想到的东西的范围，这样其实就是减小了我的熵。那么我熵的减小程度就是我的信息增益。</p>
<p>所以信息增益如果套上机器学习的话就是，如果把特征A对训练集D的信息增益记为g(D, A)的话，那么g(D, A)的计算公式就是：</p>
<p>$$g(D, A)=H(D)-H(D,A)g(D,A)=H(D)−H(D,A)$$</p>
<p>为了更好的解释熵，条件熵，信息增益的计算过程，下面通过示例来描述。假设我现在有这一个数据集，第一列是编号，第二列是性别，第三列是活跃度，第四列是客户是否流失的标签（0:表示未流失，1:表示流失）。<br><img src="https://s1.ax1x.com/2020/04/14/JS3ozF.jpg" alt="JS3ozF.jpg"><br>假如要算性别和活跃度这两个特征的信息增益的话，首先要先算总的熵和条件熵。总的熵其实非常好算，就是把标签作为随机变量X。上表中标签只有两种（0和1）因此随机变量X的取值只有0或者1。所以要计算熵就需要先分别计算标签为0的概率和标签为1的概率。从表中能看出标签为0的数据有10条，所以标签为0的概率等于2/3。标签为1的概率为1/3。所以熵为：</p>
<p>$$-(1/3)<em>log(1/3)-(2/3)</em>log(2/3)=0.9182−(1/3)∗log(1/3)−(2/3)∗log(2/3)=0.9182$$</p>
<p>接下来就是条件熵的计算，以性别为男的熵为例。表格中性别为男的数据有8条，这8条数据中有3条数据的标签为1，有5条数据的标签为0。所以根据条件熵的计算公式能够得出该条件熵为：</p>
<p>$$-(3/8)<em>log(3/8)-(5/8)</em>log(5/8)=0.9543−(3/8)∗log(3/8)−(5/8)∗log(5/8)=0.9543$$</p>
<p>根据上述的计算方法可知，总熵为：</p>
<p>$$-(5/15)<em>log(5/15)-(10/15)</em>log(10/15)=0.9182−(5/15)∗log(5/15)−(10/15)∗log(10/15)=0.9182$$</p>
<p>性别为男的熵为：</p>
<p>$$-(3/8)<em>log(3/8)-(5/8)</em>log(5/8)=0.9543−(3/8)∗log(3/8)−(5/8)∗log(5/8)=0.9543$$</p>
<p>性别为女的熵为：</p>
<p>$$-(2/7)<em>log(2/7)-(5/7)</em>log(5/7)=0.8631−(2/7)∗log(2/7)−(5/7)∗log(5/7)=0.8631$$</p>
<p>活跃度为低的熵为：</p>
<p>$$-(4/4)*log(4/4)-0=0−(4/4)∗log(4/4)−0=0$$</p>
<p>活跃度为中的熵为：</p>
<p>$$-(1/5)<em>log(1/5)-(4/5)</em>log(4/5)=0.7219−(1/5)∗log(1/5)−(4/5)∗log(4/5)=0.7219$$</p>
<p>活跃度为高的熵为：</p>
<p>$$-0-(6/6)*log(6/6)=0−0−(6/6)∗log(6/6)=0$$</p>
<p>现在有了总的熵和条件熵之后就能算出性别和活跃度这两个特征的信息增益了。</p>
<p>性别的信息增益=总的熵-(8/15)性别为男的熵-(7/15)性别为女的熵=0.0064</p>
<p>活跃度的信息增益=总的熵-(6/15)活跃度为高的熵-(5/15)活跃度为中的熵-(4/15)*活跃度为低的熵=0.6776</p>
<p>那信息增益算出来之后有什么意义呢？回到读心术的问题，为了我能更加准确的猜出你心中所想，我肯定是问的问题越好就能猜得越准！换句话来说我肯定是要想出一个信息增益最大（减少不确定性程度最高）的问题来问你。其实ID3算法也是这么想的。ID3算法的思想是从训练集D中计算每个特征的信息增益，然后看哪个最大就选哪个作为当前结点。然后继续重复刚刚的步骤来构建决策树。</p>
<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p>就是从根结点开始，对结点计算所有可能的特征的信息增益，然后选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点，然后对子结点递归执行上述的步骤直到信息增益很小或者没有特征可以继续选择为止。</p>
<p>因此，ID3算法伪代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#假设数据集为D，标签集为A，需要构造的决策树为tree</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ID3</span><span class="params">(D, A)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> D中所有的标签都相同:</span><br><span class="line">        <span class="keyword">return</span> 标签</span><br><span class="line">    <span class="keyword">if</span> 样本中只有一个特征或者所有样本的特征都一样:</span><br><span class="line">        对D中所有的标签进行计数</span><br><span class="line">        <span class="keyword">return</span> 计数最高的标签</span><br><span class="line">    计算所有特征的信息增益</span><br><span class="line">    选出增益最大的特征作为最佳特征(best_feature)</span><br><span class="line">    将best_feature作为tree的根结点</span><br><span class="line">    得到best_feature在数据集中所有出现过的值的集合(value_set)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> value_set:</span><br><span class="line">        从D中筛选出best_feature=value的子数据集(sub_feature)</span><br><span class="line">        从A中筛选出best_feature=value的子标签集(sub_label)</span><br><span class="line">        <span class="comment">#递归构造tree</span></span><br><span class="line">        tree[best_feature][value] = ID3(sub_feature, sub_label)</span><br><span class="line">    <span class="keyword">return</span> tree</span><br></pre></td></tr></table></figure>
<h3 id="使用决策树进行预测"><a href="#使用决策树进行预测" class="headerlink" title="使用决策树进行预测"></a>使用决策树进行预测</h3><p>决策树的预测思想非常简单，假设现在已经构建出了一棵用来决策是否买西瓜的决策树。<br><img src="https://www.educoder.net/api/attachments/283157"></img></p>
<p>并假设现在在水果店里有这样一个西瓜，其属性如下：<br><img src="https://s1.ax1x.com/2020/04/14/JSGEnJ.jpg" alt="JSGEnJ.jpg"><br>那买不买这个西瓜呢？只需把西瓜的属性代入决策树即可。决策树的根结点是瓤是否够红，所以就看西瓜的属性，经查看发现够红，因此接下来就看够不够冰。而西瓜不够冰，那么看是否便宜。发现西瓜是便宜的，所以这个西瓜是可以买的。</p>
<p>因此使用决策树进行预测的伪代码也比较简单，伪代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tree表示决策树，feature表示测试数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(tree, feature)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> tree是叶子结点:</span><br><span class="line">        <span class="keyword">return</span> tree</span><br><span class="line">    根据feature中的特征值走入tree中对应的分支</span><br><span class="line">    <span class="keyword">if</span> 分支依然是课树:</span><br><span class="line">        result = predict(分支, feature)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding=utf8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 计算熵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcInfoEntropy</span><span class="params">(label)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        label(narray):样本标签</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        InfoEntropy(float):熵</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#********* Begin *********#</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算标签在数据集中出现的概率</span></span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> label:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">            dic[i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dic[i] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 计算熵</span></span><br><span class="line">    num = len(label)</span><br><span class="line">    InfoEntropy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> dic:</span><br><span class="line">        InfoEntropy += <span class="number">-1.0</span>*dic[key]/num*np.log2(<span class="number">1.0</span>*dic[key]/num)</span><br><span class="line">    <span class="comment">#********* End *********#</span></span><br><span class="line">    <span class="keyword">return</span> InfoEntropy</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算条件熵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcHDA</span><span class="params">(feature, label, index, value)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarray):样本特征</span></span><br><span class="line"><span class="string">        label(ndarray):样本标签</span></span><br><span class="line"><span class="string">        index(int):需要使用的特征列索引</span></span><br><span class="line"><span class="string">        value(int):index所表示的特征列中需要考察的特征值</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        HDA(float):信息熵</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#********* Begin *********#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># sub_feature和sub_label表示根据特征列和特征值分割出的子数据集中的特征和标签</span></span><br><span class="line">    sub_feature = []</span><br><span class="line">    sub_label = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(feature)):</span><br><span class="line">        <span class="keyword">if</span> feature[i,index] == value:</span><br><span class="line">            sub_feature.append(feature[i])</span><br><span class="line">            sub_label.append(label[i])</span><br><span class="line"></span><br><span class="line">    sub_feature = np.array(sub_feature)</span><br><span class="line">    sub_label = np.array(sub_label)</span><br><span class="line">    HDA = calcInfoEntropy(sub_label)</span><br><span class="line">    <span class="comment">#********* End *********#</span></span><br><span class="line">    <span class="keyword">return</span> HDA</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算信息增益</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcInfoGain</span><span class="params">(feature, label, index)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarry):测试用例中字典里的feature</span></span><br><span class="line"><span class="string">        label(ndarray):测试用例中字典里的label</span></span><br><span class="line"><span class="string">        index(int):测试用例中字典里的index，即feature部分特征列的索引。该索引指的是feature中第几个特征，如index:0表示使用第一个特征来计算信息增益。</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        InfoGain(float):信息增益</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#********* Begin *********#</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 得到指定特征列的值的集合</span></span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> feature[:,index]:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">            dic[i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dic[i] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算条件熵</span></span><br><span class="line">    HDA = <span class="number">0</span></span><br><span class="line">    num = len(feature)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> dic:</span><br><span class="line">        HDA += <span class="number">1.0</span>*dic[key]/num*calcHDA(feature,label,index,key)</span><br><span class="line">    <span class="comment"># 计算信息增益</span></span><br><span class="line">    InfoGain = calcInfoEntropy(label) - HDA</span><br><span class="line">    <span class="comment">#********* End *********#</span></span><br><span class="line">    <span class="keyword">return</span> InfoGain</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#&#123;'feature':[[0, 1], [1, 0], [1, 2], [0, 0], [1, 1]], 'label':[0, 1, 0, 0, 1], 'index': 0&#125;</span></span><br><span class="line"><span class="comment">#0.419973</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getBestFeature</span><span class="params">(feature, label)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarray):样本特征</span></span><br><span class="line"><span class="string">        label(ndarray):样本标签</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        best_feature(int):信息增益最高的特征</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#*********Begin*********#</span></span><br><span class="line">    maxInfoGain,opIndex = <span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> range(feature.shape[<span class="number">1</span>]):</span><br><span class="line">        infoGain = calcInfoGain(feature,label,index)</span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; maxInfoGain:</span><br><span class="line">            maxInfoGain = infoGain</span><br><span class="line">            opIndex = index</span><br><span class="line">    <span class="comment">#*********End*********#</span></span><br><span class="line">    <span class="keyword">return</span> opIndex</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建决策树</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(feature, label)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        feature(ndarray):训练样本特征</span></span><br><span class="line"><span class="string">        label(ndarray):训练样本标签</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        tree(dict):决策树模型</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#*********Begin*********#</span></span><br><span class="line">    <span class="comment"># 样本里都是同一个label没必要继续分叉了</span></span><br><span class="line">    label_set = set(label)</span><br><span class="line">    <span class="keyword">if</span>(label_set.__len__()==<span class="number">1</span>):<span class="keyword">return</span> label[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 样本中只有一个特或者所有样本的特征都一样的话就看哪个label的票数高</span></span><br><span class="line">    flag = <span class="literal">True</span></span><br><span class="line">    arr = feature[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> arrs <span class="keyword">in</span> feature:</span><br><span class="line">        <span class="keyword">if</span> str(arr) != str(arrs) : flag = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="literal">True</span>:</span><br><span class="line">        dic = &#123;&#125;</span><br><span class="line">        MAX = <span class="number">0</span></span><br><span class="line">        l = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> label:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">                dic[i] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                dic[i] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> dic[i] &gt; MAX:</span><br><span class="line">                MAX = dic[i]</span><br><span class="line">                l = i</span><br><span class="line">        <span class="keyword">return</span> l</span><br><span class="line">    <span class="comment"># 根据信息增益拿到特征的索引</span></span><br><span class="line">    best_feature = getBestFeature(feature,label)</span><br><span class="line">    <span class="comment"># 拿到bestfeature的所有特征值</span></span><br><span class="line">    v_set = set(feature[:,best_feature])</span><br><span class="line">    <span class="comment"># 构建对应特征值的子样本集sub_feature, sub_label</span></span><br><span class="line">    tree = &#123;best_feature:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> v_set:</span><br><span class="line">        sub_feature = []</span><br><span class="line">        sub_label = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(feature)):</span><br><span class="line">            <span class="keyword">if</span> feature[i][best_feature] == value:</span><br><span class="line">                sub_feature.append(feature[i])</span><br><span class="line">                sub_label.append(label[i])</span><br><span class="line"></span><br><span class="line">        sub_feature = np.array(sub_feature)</span><br><span class="line">        sub_label = np.array(sub_label)</span><br><span class="line">        <span class="comment"># 递归构建决策树</span></span><br><span class="line">        tree[best_feature][value] = createTree(sub_feature,sub_label)</span><br><span class="line">    <span class="comment">#*********End*********#</span></span><br><span class="line">    <span class="keyword">return</span> tree</span><br><span class="line"></span><br><span class="line"><span class="comment">#决策树分类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dt_clf</span><span class="params">(train_feature,train_label,test_feature)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    input:</span></span><br><span class="line"><span class="string">        train_feature(ndarray):训练样本特征</span></span><br><span class="line"><span class="string">        train_label(ndarray):训练样本标签</span></span><br><span class="line"><span class="string">        test_feature(ndarray):测试样本特征</span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        predict(ndarray):测试样本预测标签</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#*********Begin*********#</span></span><br><span class="line">    <span class="comment">#创建决策树</span></span><br><span class="line">    nowTree = createTree(train_feature,train_label)</span><br><span class="line">    <span class="comment">#print(tree)</span></span><br><span class="line">    <span class="comment">#根据tree与特征进行分类</span></span><br><span class="line">    predict = []</span><br><span class="line">    <span class="keyword">for</span> arr <span class="keyword">in</span> test_feature:</span><br><span class="line">        tree = nowTree.copy()</span><br><span class="line">        print(tree)</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">            <span class="comment">#print(tree)</span></span><br><span class="line">            <span class="keyword">if</span> type(tree).__name__ != <span class="string">'dict'</span>:</span><br><span class="line">                predict.append(tree)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            keyList = list(tree.keys())</span><br><span class="line">            firstF = keyList[<span class="number">0</span>]</span><br><span class="line">            tree = tree[firstF][arr[firstF]]</span><br><span class="line">    <span class="comment">#*********End*********#</span></span><br><span class="line">    <span class="keyword">return</span> predict</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">x = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">train_feature,test_feature,train_label,test_label = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">666</span>)</span><br><span class="line">predict = dt_clf(test_feature,train_label,test_feature)</span><br><span class="line">print(predict)</span><br></pre></td></tr></table></figure>

        </div>
        
        
        
    </div>
</div>















    


    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-09T09:18:24.110Z">2020-04-09</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    9 分钟 读完 (大约 1303 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/09/educoder%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%EF%BC%89/">educoder数据挖掘算法原理与实践：线性回归（房价预测）</a>
            
        </h1>
        <div class="content">
            <h3 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h3><p>波士顿房价数据集共有506条波斯顿房价的数据，每条数据包括对指定房屋的13项数值型特征和目标房价组成。我们需要通过数据特征来对目标房价进行预测。<br>数据集中部分数据与标签如下图所示:</p>
        </div>
        
        
        <div class="level is-mobile">
            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2020/04/09/educoder%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%EF%BC%89/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>















    


    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-03-06T08:29:49.015Z">2020-03-06</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 分钟 读完 (大约 886 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/03/06/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%9C%E4%B8%9A%E4%BA%8C/">神经网络作业二</a>
            
        </h1>
        <div class="content">
            <h3 id="题意"><a href="#题意" class="headerlink" title="题意"></a><strong>题意</strong></h3><p>考虑以下的二类训练样本集</p>
<table>
<thead>
<tr>
<th>Instance</th>
<th>Feature vector</th>
<th>Output label</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>(0,0)</td>
<td>+</td>
</tr>
<tr>
<td>2</td>
<td>(1,0)</td>
<td>+</td>
</tr>
<tr>
<td>3</td>
<td>(0,1)</td>
<td>-</td>
</tr>
<tr>
<td>4</td>
<td>(-1,0)</td>
<td>-</td>
</tr>
<tr>
<td>5</td>
<td>(1,-1)</td>
<td>-</td>
</tr>
</tbody></table>
<p>对此训练样本集，我们需要训练一个三层神经网络（输入层、单隐层、输出层），其中单隐层的单元（神经元）数目设为2，激活函数（activation function）为Sigmoid函数：</p>
        </div>
        
        
        <div class="level is-mobile">
            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2020/03/06/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%9C%E4%B8%9A%E4%BA%8C/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>















    


    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-03-05T07:51:29.114Z">2020-03-05</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    3 分钟 读完 (大约 450 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/03/05/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%9C%E4%B8%9A%E4%B8%80/">神经网络作业一</a>
            
        </h1>
        <div class="content">
            <h4 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h4><p><img src="https://files.catbox.moe/2xsf5y.jpg"></img></p>
        </div>
        
        
        <div class="level is-mobile">
            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2020/03/05/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%9C%E4%B8%9A%E4%B8%80/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>















    


    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-03-03T07:35:15.429Z">2020-03-03</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    10 分钟 读完 (大约 1504 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/03/03/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98-fpGrowth%E7%AE%97%E6%B3%95/">关联规则挖掘-fpGrowth算法</a>
            
        </h1>
        <div class="content">
            <h3 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h3><h4 id="什么是关联规则？"><a href="#什么是关联规则？" class="headerlink" title="什么是关联规则？"></a>什么是关联规则？</h4><p>见 <a href="http://seven7.xyz/2020/03/03/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98-apriori%E7%AE%97%E6%B3%95/">Apriori算法</a></p>
<h4 id="几个重要概念"><a href="#几个重要概念" class="headerlink" title="几个重要概念"></a>几个重要概念</h4><p>见 <a href="http://seven7.xyz/2020/03/03/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98-apriori%E7%AE%97%E6%B3%95/">Apriori算法</a></p>
<h4 id="fp-growth算法介绍"><a href="#fp-growth算法介绍" class="headerlink" title="fp-growth算法介绍"></a>fp-growth算法介绍</h4><ul>
<li>打开你的搜索引擎，输入一个单词或一部分，例如“我”，搜索引擎可能会去统计和“我”一块出现得多的词，然后返回给你。其实就是去找频繁项集，而且需要相当地高效，像Apriori那样的速度肯定是不行的了。
        </div>
        
        
        <div class="level is-mobile">
            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2020/03/03/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98-fpGrowth%E7%AE%97%E6%B3%95/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>















    


    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-03-03T07:34:45.537Z">2020-03-03</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    9 分钟 读完 (大约 1305 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/03/03/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98-apriori%E7%AE%97%E6%B3%95/">关联规则挖掘-apriori算法</a>
            
        </h1>
        <div class="content">
            <h3 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h3><h4 id="什么是关联规则？"><a href="#什么是关联规则？" class="headerlink" title="什么是关联规则？"></a>什么是关联规则？</h4><p>关联规则分析也称为购物篮分析，最早是为了发现超市销售数据库中不同的商品之间的关联关系。关联规则是反映一个事物与其他事物之间的关联性，若多个事物之间存在着某种关联关系，那么其中的一个事物就能通过其他事物预测到。<br>举个例子：在超市中，经常发现啤酒和尿布经常在同一张购物清单上出现，那是因为买尿裤的一般是有孩子的中年男性，他们在超市给孩子买尿裤时，会买上几瓶啤酒来犒劳自己，于是啤酒和尿布就相互关联。</p>
        </div>
        
        
        <div class="level is-mobile">
            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2020/03/03/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98-apriori%E7%AE%97%E6%B3%95/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>















    


    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-02-27T14:18:25.447Z">2020-02-27</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    15 分钟 读完 (大约 2228 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/02/27/Cart%E6%A0%91%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/">Cart树的原理及实现</a>
            
        </h1>
        <div class="content">
            <h2 id="CART在回归预测上的原理及实现"><a href="#CART在回归预测上的原理及实现" class="headerlink" title="CART在回归预测上的原理及实现"></a>CART在回归预测上的原理及实现</h2><h3 id="1-CART简介"><a href="#1-CART简介" class="headerlink" title="1.CART简介"></a>1.CART简介</h3><p>CART是指分类回归树，Classfication And Regression Tree，缩写为CART,CART算法采用二分递归分割的技术将当前样本集分为两个子样本集，使得生成的每个非叶子节点都有两个分支。所以CART的结构是二叉树，CART可以处理连续型变量和离散型变量，利用<strong>训练数据</strong>递归的划分特征空间进行建树，用<strong>验证数据</strong>进行剪枝。</p>
<ul>
<li>如果待预测分类是<strong>离散型</strong>数据，则CART生成分类决策树。</li>
<li>如果待预测分类是<strong>连续性</strong>数据，则CART生成回归决策树。
        </div>
        
        
        <div class="level is-mobile">
            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2020/02/27/Cart%E6%A0%91%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>















    


    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-02-19T04:34:06.263Z">2020-02-19</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 分钟 读完 (大约 600 个字)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/02/19/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/">贝叶斯分类器</a>
            
        </h1>
        <div class="content">
            <blockquote>
<p>地震预报是比较困难的一个课题,可以根据地震与生物异常反应之间的联系来进行研究。根据历史记录的统计,地震前一周内出现生物异常反应的概率为50%,而一周内没有发生地震但也出现了生物异常反应的概率为 10%。假设某 一个地区属于地震高发区,发生地震的概率为 20%。问:如果某日观察到明显的生物异常反应现象,是否应当预报一周内将发生地震?</p>
</blockquote>
        </div>
        
        
        <div class="level is-mobile">
            <div class="level-start">
                <div class="level-item">
                <a class="button is-size-7 is-light" href="/2020/02/19/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/#more">阅读更多</a>
                </div>
            </div>
        </div>
        
        
    </div>
</div>















    


</div>
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="" src="/images/avatar.jpg" alt="Wenze Qiu">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Wenze Qiu
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        SDUST SE
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>ShanDong,QingDao</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        文章
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            13
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        分类
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            4
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        标签
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            11
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/wenze7" target="_blank" rel="noopener">
                关注我</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Github" href="https://github.com/wenze7">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Weibo" href="https://weibo.com/5663670406/profile?topnav=1&amp;wvr=6">
                
                <i class="fab fa-weibo"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Zhihu" href="https://www.zhihu.com/people/pengqiu7">
                
                <i class="fab fa-zhihu"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="QQ" href="http://wpa.qq.com/msgrd?v=3&amp;uin=1245666720&amp;site=qq&amp;menu=yes">
                
                <i class="fab fa-qq"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Twitter" href="http://www.baidu.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            链接
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://catbox.moe" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">catbox</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">catbox.moe</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://blog.csdn.net/Insist_77" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">CSDN</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">blog.csdn.net</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                分类
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
            <span class="level-start">
                <span class="level-item">学习笔记</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E6%95%99%E7%A8%8B/">
            <span class="level-start">
                <span class="level-item">教程</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">
            <span class="level-start">
                <span class="level-item">数据挖掘</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">8</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%E8%B5%84%E6%BA%90%E6%80%BB%E7%BB%93/">
            <span class="level-start">
                <span class="level-item">资源总结</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            标签云
        </h3>
        <a href="/tags/CART/" style="font-size: 10px;">CART</a> <a href="/tags/ID/" style="font-size: 10px;">ID</a> <a href="/tags/MAC/" style="font-size: 15px;">MAC</a> <a href="/tags/educoder/" style="font-size: 15px;">educoder</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/%E4%B8%8D%E5%AE%9A%E6%97%B6%E6%9B%B4%E6%96%B0/" style="font-size: 10px;">不定时更新</a> <a href="/tags/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98/" style="font-size: 15px;">关联规则挖掘</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 20px;">决策树</a> <a href="/tags/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">多元线性回归</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 10px;">爬虫</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">神经网络</a>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            归档
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">四月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">三月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">5</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">二月 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
        </div>
    
</div>

                
            </div>
        </div>
    </section>
    

<footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    Seven7
                
                </a>
                <p class="is-size-7">
                &copy; 2020 QiuPeng&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
   
</footer>



    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("zh-CN");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'http://yoursite.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="回到顶端" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="想要查找什么..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
